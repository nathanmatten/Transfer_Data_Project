---
title: "Transfer_analysis"
author: "Nathan Matten"
date: "`r Sys.Date()`"
output:
  html_document: 
    number_sections: yes
    toc: yes
    toc_float: yes
    fig_caption: yes
    fig_width: 6
    fig_height: 4
    code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, results = 'hide')
set.seed(2141122)
```

```{r Package Loading}
library(tidyverse)
library(toRvik)
library(caret)
library(corrplot)
```

# Data Loading and Wrangling
## Data Loading
### Transfer Players dataframe
The code below creates the transfer_players dataset, as well as removes the players that transferred to and from outside d1
```{r Data Loading}
transfer_players <- transfer_portal(year = 2017) %>% 
  rbind(transfer_portal(year = 2018)) %>% 
  rbind(transfer_portal(year = 2019)) %>% 
  rbind(transfer_portal(year = 2020)) %>% 
  rbind(transfer_portal(year = 2021)) %>% 
  rbind(transfer_portal(year = 2022)) %>% 
  select(-source) %>% 
  filter(from_d1 == TRUE, to_d1 == TRUE)
# Removed players that transferred to and from outside D1 -- I don't believe they're part of our study currently (but they can definitely be added back in)... although this removes about 900 player transfers
```
### Player stats dataframe
We now create a giant player_stats table with all players from seasons 2015 through 2022
```{r Player Stats}
player_stats <- bart_player_season(year = 2017, stat = 'all') %>%   
  rbind(bart_player_season(year = 2018, stat = 'all')) %>%
  rbind(bart_player_season(year = 2019, stat = 'all')) %>%
  rbind(bart_player_season(year = 2020, stat = 'all')) %>%
  rbind(bart_player_season(year = 2021, stat = 'all')) %>%
  rbind(bart_player_season(year = 2022, stat = 'all')) %>% 
  rbind(bart_player_season(year = 2016, stat = 'all')) %>% 
  rbind(bart_player_season(year = 2015, stat = 'all'))
```
### Conference Ratings Dataframe
In order to calculate the conf_diff stat, we need a dataframe with the conference ratings. That is created below.
```{r Conference Ratings}
conf_ratings <- read.csv(file = "~/Documents/GitHub/Transfer_Data_Pitt/kenpom_ratings_16_22.csv")
colnames(conf_ratings) <- c("Conference","2016","2017","2018","2019","2020","2021","2022")
conf_ratings$Conference[conf_ratings$Conference == "Horizon"] <- "Horz" 
conf_ratings$Conference[conf_ratings$Conference == "Sun Belt"] <- "SB"
conf_ratings$Conference[conf_ratings$Conference == "Big East"] <- "BE"
conf_ratings$Conference[conf_ratings$Conference == "Big West"] <- "BW"
conf_ratings$Conference[conf_ratings$Conference == "Big Sky"] <- "BSky" 
conf_ratings$Conference[conf_ratings$Conference == "Atlantic 10"] <- "A10"
conf_ratings$Conference[conf_ratings$Conference == "Northeast"] <- "NEC"
conf_ratings$Conference[conf_ratings$Conference == "American East"] <- "AE"
conf_ratings$Conference[conf_ratings$Conference == "Patriot"] <- "Pat"
conf_ratings$Conference[conf_ratings$Conference == "Southern"] <- "SC"
conf_ratings$Conference[conf_ratings$Conference == "Summit"] <- "Sum"
conf_ratings$Conference[conf_ratings$Conference == "Big 12"] <- "B12"
conf_ratings$Conference[conf_ratings$Conference == "C-USA"] <- "CUSA"
conf_ratings$Conference[conf_ratings$Conference == "Big 10"] <- "B10"
conf_ratings$Conference[conf_ratings$Conference == "Big South"] <- "BSth" 
conf_ratings$Conference[conf_ratings$Conference == "Southland"] <- "Slnd" 
conf_ratings$Conference[conf_ratings$Conference == "ASUN"] <- "ASun" 
conf_ratings$Conference[conf_ratings$Conference == "Ohio Valley"] <- "OVC"
conf_ratings$Conference[conf_ratings$Conference == "Pac 12"] <- "P12"
conf_ratings$Conference[conf_ratings$Conference == "AAC"] <- "Amer"
```

## Data Wrangling/Merging
### Data Set for transferred players
Working through merging tables to create a master table with all stats for transfer players from the season before they transferred to the season after transfer.
```{r Data Wrangling/Merging}
player_stats <- player_stats %>% 
  dplyr::select(id,player,team,conf,g,year,usg,ortg,efg,ts,ftm,fta,ft_pct,two_m,two_a,two_pct,three_m,three_a,three_pct,oreb_rate,dreb_rate,bpm,ast,ast_to,to,blk,stl)
team_mapping <- unique(player_stats[,c("team", "conf")]) %>% 
  arrange(conf, team)
transfer_players <- merge(transfer_players, team_mapping, by.x = "from", by.y = "team", all.x = TRUE, all.y = FALSE) %>% 
  select(-c(exp, from_d1, to_d1))
transfer_players <- merge(transfer_players, team_mapping, by.x = "to", by.y = "team", all.x = TRUE, all.y = FALSE)
transfer_players <- transfer_players %>% 
  mutate(old_conf = conf.x) %>% 
  mutate(new_conf = conf.y) %>% 
  select(id,player,year,from,old_conf,to,new_conf,imm_elig,sit) %>% 
  arrange(year,old_conf,new_conf,player)
temp <- merge(transfer_players,player_stats, by.x = "id", by.y = "id", all.x = TRUE)  %>% 
  filter(year.x == year.y, team == to.x, conf == new_conf)  %>% 
  arrange(id, old_conf, year.x, year.y, new_conf) %>% 
  distinct
temp_1 <- merge(transfer_players,player_stats, by.x = "id", by.y = "id", all.x = TRUE)  %>% 
  mutate("year_1" = year.x -1) %>% 
  filter(year_1 == year.y, team == from, conf == old_conf)  %>% 
  arrange(id, old_conf, year.x, year.y, new_conf) %>% 
  select(-"year_1") %>% 
  distinct
temp_2 <- merge(transfer_players,player_stats, by.x = "id", by.y = "id", all.x = TRUE)  %>% 
  mutate("year_2" = year.x - 2) %>% 
  filter(year_2 == year.y, team == from, conf == old_conf)  %>% 
  arrange(id, old_conf, year.x, year.y, new_conf) %>% 
  select(-"year_2") %>% 
  distinct
temp.1 <- merge(transfer_players,player_stats, by.x = "id", by.y = "id", all.x = TRUE)  %>% 
  mutate("year1" = year.x + 1) %>% 
  filter(year1 == year.y, team == to.x, conf == new_conf)  %>% 
  arrange(id, old_conf, year.x, year.y, new_conf) %>% 
  select(-"year1") %>%
  distinct
temp2 <- rbind(temp,temp_1,temp_2,temp.1) %>% 
  arrange(id, old_conf, year.x, year.y, new_conf)
temp_post <- temp2 %>% 
  group_by(id) %>%
  arrange(id, desc(year.y)) %>% 
  filter(to.x == team) %>% 
  slice(1) %>% 
  ungroup()
temp_pre <- temp2 %>% 
  group_by(id) %>%
  arrange(id, desc(year.y)) %>% 
  filter(to.x != team) %>% 
  slice(1) %>% 
  ungroup()
diff1 <- setdiff(temp_pre$id,temp_post$id)
diff2 <- setdiff(temp_post$id, temp_pre$id)
missing <- rbind(transfer_players[transfer_players$id %in% diff1,],transfer_players[transfer_players$id %in% diff2,])
missing <-  (missing$id)
for (i in 1:length(missing)){
  temp_pre <- subset(temp_pre, temp_pre$id != missing[i])
  temp_post <- subset(temp_post, temp_post$id != missing[i])
}
temp2 <- cbind(temp_pre,temp_post)
diff3 <- setdiff(transfer_players$id,temp2$id)
length(diff3)
master <- temp2
```
### Final Data Set
Consolidating the master table into the stats we will want to use, as well as creating the conf_diff stat
```{r Final Data Set, cache=TRUE, warning=FALSE}
#Creating final dataset
transfer_stats <- master[,c(1:9,11:18,28:35,46:49,65)]
colnames(transfer_stats) <- c("id","player","tran_year","from_uni","old_conf","to_uni","new_conf","imm_elig","sit","team","conf","g","from_year","usg","ortg","efg","ts","oreb_rate","dreb_rate","bpm","ast_rate","ast_to","to_rate","blk_rate","stl_rate","new_team","conf2","g2","a_year","bpm2")
transfer_stats <- transfer_stats %>%  filter(from_year != 2015)
# Retrieving conference differences (multiple steps)
# 1: Getting old conference kenpom rating
transfer_stats <- merge(transfer_stats, conf_ratings, by.x = "old_conf", by.y = "Conference", all.x = TRUE, all.y = FALSE)
temp4 <- transfer_stats[,c(3,13,31:37)]
temp_col <- temp4$from_year
for(i in 1:length(temp_col)){
    temp_col[i] <- temp4[1,grepl(temp_col[i], colnames(temp4))]
}
ratings <- matrix()
ratings$ratings_old <- temp_col
# 2: Getting new conference kenpom rating
transfer_stats <- transfer_stats[,c(1:30)] 
transfer_stats <-  merge(transfer_stats, conf_ratings, by.x = "conf2", by.y = "Conference", all.x = TRUE, all.y = FALSE)
temp5 <- transfer_stats[,c(29,31:37)]
temp_col <- temp5$a_year
for(i in 1:length(temp_col)){
    temp_col[i] <- temp5[1,grepl(temp_col[i], colnames(temp5))]
}
ratings$ratings_new <- temp_col
remove(temp4)
remove(temp5)
ratings <- ratings[-1]
# 3: Getting difference from new conference to old conference and adding to dataset
ratings$diff <- ratings$ratings_old - ratings$ratings_new
transfer_stats <- transfer_stats[,c(1:30)] 
transfer_stats$conf_diff <- ratings$diff
# Final dataset with only number values
final_stats <- transfer_stats[,c(13,15:22,24:26,30,31,1:3)]
```
# Analysis
## Model Selection
### Correlation
```{r Correlation}
corrplot(cor(final_stats[,c(1:12,14)]))
```

It appears that TS, eFg, and ortg are all highly correlated (as expected), and we should remove all but 1 of them. I believe we should either use TS or ortg, but it looks like ortg is negatively related to to_rate, so let's go with TS%.  

```{r Correlation 2}
corrplot(cor(final_stats[,c(1,2,5:12,14)]))
```

TS and BPM are both still related, but I think it's small enough that we can move forward with additional selection

### AIC Predictor selection
```{r AIC Predictors, cache=FALSE}
library(MASS)
dat_reg <- final_stats %>% dplyr::select(g,usg,ts,oreb_rate,dreb_rate,bpm,ast_rate,to_rate,blk_rate,stl_rate,bpm2,conf_diff)
indexes <- createDataPartition(dat_reg$bpm2, p = .8, list = F)
train <- dat_reg[indexes, ]
test <- dat_reg[-indexes, ]

train_x <- train[,c(1,2,3,6)]
train_y <- train[,11]

test_x <- test[,c(1,2,3,6)]
test_y <- test[,11]

full.fit <- lm(bpm2 ~ ., data = dat_reg)
base.fit <- lm(bpm2 ~ 1, data=dat_reg)
summary(full.fit)
# Just based on full fit, it appears, that the variables we should keep are g, usg, ts, bpm, and maybe stl_rate...
fit.aic <- stepAIC(base.fit, direction = 'both', scope = list(upper = full.fit, lower = base.fit))
# It appears that AIC fit has the same 5 predictors mentioned above...
# We can also add dreb_rate... but it would appear that conf_diff is not significant regardless
mod1 <- lm(bpm2 ~ bpm + g + usg + ts + stl_rate + dreb_rate, data = dat_reg)
mod2 <- lm(bpm2 ~ bpm + g + usg + ts + stl_rate, data = dat_reg)
mod3 <- lm(bpm2 ~ bpm + g + usg + ts, data = dat_reg)
mod4 <- lm(bpm2 ~ bpm + g + usg + ts + stl_rate + dreb_rate + ast_rate, data = dat_reg)
mod5 <- lm(bpm2 ~ bpm + g + usg + ts + stl_rate + dreb_rate + ast_rate + blk_rate, data = dat_reg)
aics <- AIC(mod1,mod2,mod3,mod4,mod5)
# The AIC is really high regardless, but mod2 and 3 are the best... I think mod3 is the best option for now
mod3_rmse <- caret::RMSE(dat_reg$bpm2,mod3$fitted.values)
```
Evaluating the full model, it appears that the variables we should fit are g, usg, ts, bpm, and possibly stl_rate, but we'll do AIC model selection to see what values are recommended.

The results from stepAIC are the same 5 variables listed above. While we may have theorized that conf_diff would make a difference, it doesn't appear to at this time.  

We tested 5 different models with different variables to see which one is the best and confirm our AIC selection. The variables included were:

+-------+------------+------------+------------+------------+------------+------------+------------+------------+
| Model |    bpm     |    g       |    usg     |    ts      |   stl_rate |  dreb_rate |  ast_rate  | blk_rate   |
+=======+============+============+============+============+============+============+============+============+
| mod1  |$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|
+-------+------------+------------+------------+------------+------------+------------+------------+------------+
| mod2  |$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|
+-------+------------+------------+------------+------------+------------+------------+------------+------------+
| mod3  |$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|
+-------+------------+------------+------------+------------+------------+------------+------------+------------+
| mod4  |$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|
+-------+------------+------------+------------+------------+------------+------------+------------+------------+
| mod5  |$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|$\checkmark$|
+-------+------------+------------+------------+------------+------------+------------+------------+------------+

The AIC values from models 1:5 are: `r knitr::kable(aics)`  
Based on the different selection criteria above, I believe we should select mod3 moving forward (for now). This means that we have just 4 predictors. 

The RMSE from mod3 is `r round(mod3_rmse,4)`


### KNN Choose k
```{r choose k}
# Now choose k
output <- data.frame(matrix(ncol=4,nrow=19))
colnames(output) <- c('MSE','MAE','RMSE','k')
# for loop to print knnreg results based on k=2:10
for (i in 2:20){
  knnmodel = knnreg(train_x,train_y,k=i)
  #cat(knnmodel,i)
  pred_y <- predict(knnmodel, data.frame(test_x))
  #cat(pred_y,i)
  output[i-1,4] <- i
  output[i-1,1] <- mean((test_y - pred_y)^2)
  output[i-1,2] <- caret::MAE(test_y,pred_y)
  output[i-1,3] <- caret::RMSE(test_y,pred_y)
  cat("KNN Model", i, ": BPM Prediction","MSE: ", output[i-1,1], "MAE: ", output[i-1,2], " RMSE: ", output[i-1,3], '\n')
}
p_mse_1 <- ggplot(data = output) +
  geom_point(aes(x = k, y = MSE), color = 'blue', show.legend = FALSE) + 
  xlab("k") +
  ylab("Error") +
  ggtitle("MSE")
p_rmse_1 <- ggplot(data = output) +
  geom_point(aes(x = k, y= RMSE), color = 'red', show.legend = FALSE) + 
  xlab("k") +
  ylab("Error") + 
  ggtitle("RMSE")
p_mae_1 <- ggplot(data = output) +
  geom_point(aes(x = k, y = MAE), color = 'green', show.legend = FALSE) +
  xlab("k") +
  ylab("Error") + 
  ggtitle("MAE")
mins <- apply(output[,1:3], 2, min)
which(output[,1] == mins[1])
which(output[,2] == mins[2])
which(output[,3] == mins[3])
# Looks like k = 19 is the best... but that seems a bit high... 
# k = 9 or k = 11 are local mins, so let's use one of those in additional analysis... I choose 9
library(gridExtra)
grid.arrange(p_mse_1,p_rmse_1,p_mae_1, nrow = 3)
```

Based on the graphs (as well as the table output from our choose K metric) we can see that we have local mins at k = 9 and k = 11. I have chosen to use the smaller k (k = 9) for future observation. The table of choose K output can be seen below:  
`r knitr::kable(output)`

## Additional analysis methods 
### LOOCV
In order to minimize RMSE, we will try using the "Leave one out" cross-validation technique (through the built in r function). We will also run a manual version of LOO in subsequent blocks.
```{r LOOCV, cache = TRUE}
ctrl <- trainControl(method = "LOOCV")
mod_loocv <- train(bpm2 ~ bpm + g + usg + ts, data = dat_reg, method = "lm", trControl = ctrl)
```

The RMSE from the internal LOOCV function is `r round(mod_loocv$results[2],4)`

### LOO 
```{r}
tran_loo <- dat_reg[,c(1,2,3,6,11)]
response_loo <- data.frame(matrix(ncol=4))
colnames(response_loo) <- c('ID','bpm2','Pred_BPM2','bpm2_diff')
for (i in 1:nrow(tran_loo)){
  train_loo <- tran_loo[-i,]
  test_loo <- tran_loo[i,c(1:4)]
  test_loo_y <- tran_loo[i,5]
  lmmodel = lm(bpm2 ~ bpm + ts + g + usg, data = train_loo)
  pred_y <- predict(lmmodel, data.frame(test_loo))
  response_loo[i,3] <- pred_y
  response_loo[i,2] <- test_loo_y
  response_loo[i,1] <- i
  response_loo[i,4] <- test_loo_y - pred_y
}
RMSE_loo <- caret::RMSE(response_loo$bpm2,response_loo$Pred_BPM2)
```

The RMSE of self-implemented "leave one out" is: `r round(RMSE_loo,4)`. This is the same as LOOCV function (which it should be - so it appears that I'm doing it correctly).

### LOO KNN
```{r}
tran_loo_k <- dat_reg[,c(1,2,3,6,11)]
response_loo_k <- data.frame(matrix(ncol=4))
colnames(response_loo_k) <- c('ID','bpm2','Pred_BPM2','bpm2_diff')
for (i in 1:nrow(tran_loo_k)){
  train_loo_k <- tran_loo_k[-i,c(1:4)]
  train_loo_yk <- tran_loo_k[-i,5]
  test_loo_k <- tran_loo_k[i,c(1:4)]
  test_loo_yk <- tran_loo_k[i,5]
  knn_loo <- knnreg(train_loo_k,train_loo_yk,k=9)
  pred_yk <- predict(knn_loo, test_loo_k)
  response_loo_k[i,3] <- pred_yk
  response_loo_k[i,2] <- test_loo_yk
  response_loo_k[i,1] <- i
  response_loo_k[i,4] <- test_loo_yk - pred_yk
}
RMSE_loo_k <- caret::RMSE(response_loo_k$bpm2,response_loo_k$Pred_BPM2)
```

The RMSE of self-implemented "leave one out KNN regression" is: `r round(RMSE_loo_k,4)`

### Extreme Gradient Boost analysis
```{r extreme gradient boosting training}
library(xgboost)
xgb_train = xgb.DMatrix(data = as.matrix(train_x), label = train_y)
xgb_test = xgb.DMatrix(data = as.matrix(test_x), label = test_y)
xgbc = xgboost(data = xgb_train, max.depth = 2, nrounds = 50)
pred_yx = predict(xgbc, xgb_test)
rmsex = caret::RMSE(test_y, pred_yx)
```

The RMSE of extreme gradient boosting training is `r rmsex`. It appears that the RMSE of the basic model (mod3) is the best, followed by LOOCV, LOO-KNN, KNN, and finally XGBT.

# Predictive Function
## Writing the function
```{r}

bpm_pred_name <- function(years = current_season(), id = NULL, name = NULL){
  require(toRvik)
    players <- bart_players(year = years)
  specific_player <- players[which((players$player == name) & players$year == years),]
  stats_hold <- bart_player_season(year = years, id = specific_player$id, stat = 'all')
  bpm2 <- mod3$coefficients[1] + mod3$coefficients[2]*stats_hold$bpm + mod3$coefficients[3]*stats_hold$g + mod3$coefficients[4]*stats_hold$usg + mod3$coefficients[5]*stats_hold$ts
  unlist(bpm2)
  if(nrow(specific_player) == 0){
    return("This player did not play that year")
  }
  else{return(cat(as.double(bpm2)))}
  } 
bpm_pred_stats <- function(bpm = NULL, g = NULL, usg = NULL, ts = NULL){
    bpm2 <- mod3$coefficients[1] + mod3$coefficients[2]*bpm + mod3$coefficients[3]*g + mod3$coefficients[4]*usg + mod3$coefficients[5]*ts
    return(cat(as.double(bpm2)))
  }
bpm_pred_name(years = 2022, name = "Baylor Scheierman")
bpm_pred_stats(7.53,33,22.6,64.3)
```

This function can now take the input of a specific year and a player name and return their predicted BPM based on transfer data... I'm curious what would happen if I added in conf_diff as a predictor and how to calculate on the fly, but that can be a future question.